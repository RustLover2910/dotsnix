s{
  // Your OpenAI API key
  "api_key": "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",
// OpenAI API endpoint
  "endpoint": "https://api.openai.com/v1",
  // Predefined prompts, use `-p` flag to switch prompt
  "prompts": {
    "default": "You are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible."
  },
  // Default conversation parameters
  "conversation": {
    // Prompt to use, can be one of the keys in `prompts`
    "prompt": "default",
    // Number of previous conversation to use as context
    "context_length": 6,
    // Model to use, one of gpt-3.5 and gpt-4 series models
    "model": "gpt-3.5-turbo",
    // What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
    "temperature": 1,
    // Whether to stream the response
    "stream": true,
    // Maximum number of tokens to generate
    "max_tokens": 4000
  }
}
